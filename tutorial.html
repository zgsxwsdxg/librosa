<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Tutorial &mdash; librosa 0.3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootswatch-3.1.0/yeti/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.1.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="librosa 0.3.0 documentation" href="index.html" />
    <link rel="next" title="Package reference" href="librosa.html" />
    <link rel="prev" title="Installation instructions" href="install.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          LibROSA</a>
        <span class="navbar-text navbar-version pull-left"><b>0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            <li class="divider-vertical"></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation instructions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="librosa.html">Package reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Tutorial</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#quickstart">Quickstart</a></li>
<li><a class="reference internal" href="#advanced-usage">Advanced usage</a></li>
<li><a class="reference internal" href="#more-examples">More examples</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="install.html" title="Previous Chapter: Installation instructions"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm">&laquo; Installation ins...</span>
    </a>
  </li>
  <li>
    <a href="librosa.html" title="Next Chapter: Package reference"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm">Package referenc... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>This section covers the fundamentals of developing with <em>librosa</em>, including
a package overview, basic and advanced usage, and integration with the <em>scikit-learn</em>
package.  We will assume basic familiarity with Python and NumPy/SciPy.</p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The <em>librosa</em> package is structured as collection of submodules:</p>
<blockquote>
<div><ul>
<li><p class="first">librosa</p>
<ul>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#beat"><em>librosa.beat</em></a></dt>
<dd><p class="first last">Functions for estimating tempo and detecting beat events.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#chord"><em>librosa.chord</em></a></dt>
<dd><p class="first last">This submodule contains a generic class which implements supervised training
of Gaussian-emission Hidden Markov Models (HMM) commonly used in chord
recognition.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#core"><em>librosa.core</em></a></dt>
<dd><p class="first last">Core functionality includes functions to load audio from disk, compute various
spectrogram representations, and a variety of commonly used tools for
music analysis.  For convenience, all functionality in this submodule is
directly accessible from the top-level <tt class="docutils literal"><span class="pre">librosa.*</span></tt> namespace.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#decompose"><em>librosa.decompose</em></a></dt>
<dd><p class="first last">Functions for harmonic-percussive source separation (HPSS) and generic
spectrogram decomposition using matrix decomposition methods implemented in
<em>scikit-learn</em>.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#display"><em>librosa.display</em></a></dt>
<dd><p class="first last">Visualization and display routines using <cite>matplotlib</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#effects"><em>librosa.effects</em></a></dt>
<dd><p class="first last">Time-domain audio processing, such as pitch shifting and time stretching.
This submodule also provides time-domain wrappers for the <cite>decompose</cite>
submodule.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#feature"><em>librosa.feature</em></a></dt>
<dd><p class="first last">Feature extraction and manipulation.  This includes low-level feature
extraction, such as chromagrams, pseudo-constant-Q (log-frequency) transforms,
Mel spectrogram, MFCC, and tuning estimation.  Also provided are feature
manipulation methods, such as delta features, memory embedding, and
event-synchronous feature alignment.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#filters"><em>librosa.filters</em></a></dt>
<dd><p class="first last">Filter-bank generation (chroma, pseudo-CQT, CQT, etc.).  These are primarily
internal functions used by other parts of <em>librosa</em>.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#onset"><em>librosa.onset</em></a></dt>
<dd><p class="first last">Onset detection and onset strength computation.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#output"><em>librosa.output</em></a></dt>
<dd><p class="first last">Text- and wav-file output.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#segment"><em>librosa.segment</em></a></dt>
<dd><p class="first last">Functions useful for structural segmentation, such as recurrence matrix
construction, time-lag representation, and sequentially constrained
clustering.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><a class="reference internal" href="librosa.html#util"><em>librosa.util</em></a></dt>
<dd><p class="first last">Helper utilities (normalization, padding, centering, etc.)</p>
</dd>
</dl>
</li>
</ul>
</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="quickstart">
<span id="id1"></span><h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h2>
<p>Before diving into the details, we&#8217;ll walk through a brief example program</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class="code"><div class="highlight"><pre><span class="c"># Beat tracking example</span>
<span class="kn">import</span> <span class="nn">librosa</span>

<span class="c"># 1. Get the file path to the included audio example</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">example_audio_file</span><span class="p">()</span>

<span class="c"># 2. Load the audio as a waveform `y`</span>
<span class="c">#    Store the sampling rate as `sr`</span>
<span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

<span class="c"># 3. Run the default beat tracker, using a hop length of 64 frames</span>
<span class="c">#    (64 frames at sr=22.050KHz ~= 2.9ms)</span>
<span class="n">hop_length</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">tempo</span><span class="p">,</span> <span class="n">beat_frames</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">beat</span><span class="o">.</span><span class="n">beat_track</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>

<span class="k">print</span> <span class="s">&#39;Estimated tempo: </span><span class="si">%0.2f</span><span class="s"> beats per minute&#39;</span> <span class="o">%</span> <span class="n">tempo</span>

<span class="c"># 4. Convert the frame indices of beat events into timestamps</span>
<span class="n">beat_times</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">frames_to_time</span><span class="p">(</span><span class="n">beat_frames</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>

<span class="k">print</span> <span class="s">&#39;Saving output to beat_times.csv&#39;</span>
<span class="n">librosa</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">times_csv</span><span class="p">(</span><span class="s">&#39;beat_times.csv&#39;</span><span class="p">,</span> <span class="n">beat_times</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>The first step of the program:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">filename</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">example_audio_file</span><span class="p">()</span>
</pre></div>
</div>
<p>gets the path to the audio example file included with <em>librosa</em>.  After this step,
<tt class="docutils literal"><span class="pre">filename</span></tt> will be a string variable containing the path to the example mp3.</p>
<p>The second step:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>loads and decodes the audio as a <a class="reference internal" href="glossary.html#term-time-series"><em class="xref std std-term">time series</em></a> <tt class="docutils literal"><span class="pre">y</span></tt>, represented as a one-dimensional
NumPy floating point array.  The variable <tt class="docutils literal"><span class="pre">sr</span></tt> contains the <a class="reference internal" href="glossary.html#term-sampling-rate"><em class="xref std std-term">sampling rate</em></a> of
<tt class="docutils literal"><span class="pre">y</span></tt>, that is, the number of samples per second of audio.  By default, all audio is
mixed to mono and resampled to 22050 Hz at load time.  This behavior can be overridden
by supplying additional arguments to <tt class="docutils literal"><span class="pre">librosa.load()</span></tt>.</p>
<p>The next line:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">hop_length</span> <span class="o">=</span> <span class="mi">64</span>
</pre></div>
</div>
<p>sets the <a class="reference internal" href="glossary.html#term-hop-length"><em class="xref std std-term">hop length</em></a> for the subsequent analysis.  This is number of samples to
advance between subsequent audio frames.  Here, we&#8217;ve set the hop length to 64
samples, which at 22KHz, comes to <tt class="docutils literal"><span class="pre">64.0</span> <span class="pre">/</span> <span class="pre">22050</span> <span class="pre">~=</span> <span class="pre">2.9ms</span></tt>.</p>
<p>Next, we run the beat tracker using the specified hop length:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">tempo</span><span class="p">,</span> <span class="n">beat_frames</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">beat</span><span class="o">.</span><span class="n">beat_track</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>
</pre></div>
</div>
<p>The output of the beat tracker is an estimate of the tempo (in beats per minute),
and an array of frame numbers corresponding to detected beat events.</p>
<p><a class="reference internal" href="glossary.html#term-frame"><em class="xref std std-term">Frames</em></a> here correspond to short windows of the signal (<tt class="docutils literal"><span class="pre">y</span></tt>), each
separated by <tt class="docutils literal"><span class="pre">hop_length</span></tt> samples.  Since v0.3, <em>librosa</em> uses centered frames, so
that the <em>k</em>th frame is centered around sample <tt class="docutils literal"><span class="pre">k</span> <span class="pre">*</span> <span class="pre">hop_length</span></tt>.</p>
<p>The next operation converts the frame numbers <tt class="docutils literal"><span class="pre">beat_frames</span></tt> into timings:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">beat_times</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">frames_to_time</span><span class="p">(</span><span class="n">beat_frames</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, <tt class="docutils literal"><span class="pre">beat_times</span></tt> will be an array of timestamps (in seconds) corresponding to
detected beat events.</p>
<p>Finally, we can store the detected beat timestamps as a comma-separated values (CSV)
file:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">librosa</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">times_csv</span><span class="p">(</span><span class="s">&#39;beat_times.csv&#39;</span><span class="p">,</span> <span class="n">beat_times</span><span class="p">)</span>
</pre></div>
</div>
<p>The contents of <tt class="docutils literal"><span class="pre">beat_times.csv</span></tt> should look like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="mf">0.067</span>
<span class="mf">0.514</span>
<span class="mf">0.990</span>
<span class="mf">1.454</span>
<span class="mf">1.910</span>
<span class="o">...</span>
</pre></div>
</div>
<p>This is primarily useful for visualization purposes (e.g., using
<a class="reference external" href="http://www.sonicvisualiser.org">Sonic Visualiser</a>) or evaluation (e.g., using
<a class="reference external" href="https://github.com/craffel/mir_eval">mir_eval</a>).</p>
</div>
<div class="section" id="advanced-usage">
<h2>Advanced usage<a class="headerlink" href="#advanced-usage" title="Permalink to this headline">¶</a></h2>
<p>Here we&#8217;ll cover a more advanced example, integrating harmonic-percussive separation,
multiple spectral features, and beat-synchronous feature aggregation.</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre></div></td><td class="code"><div class="highlight"><pre><span class="c"># Feature extraction example</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">librosa</span>

<span class="c"># Load the example clip</span>
<span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">librosa</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">example_audio_file</span><span class="p">())</span>

<span class="c"># Separate harmonics and percussives into two waveforms</span>
<span class="n">y_harmonic</span><span class="p">,</span> <span class="n">y_percussive</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">effects</span><span class="o">.</span><span class="n">hpss</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c"># Set the hop length</span>
<span class="n">hop_length</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c"># Beat track on the percussive signal</span>
<span class="n">tempo</span><span class="p">,</span> <span class="n">beat_frames</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">beat</span><span class="o">.</span><span class="n">beat_track</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_percussive</span><span class="p">,</span>
                                             <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
                                             <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>

<span class="c"># Compute MFCC features from the raw signal</span>
<span class="n">mfcc</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">mfcc</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="c"># And the first-order differences (delta features)</span>
<span class="n">mfcc_delta</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">delta</span><span class="p">(</span><span class="n">mfcc</span><span class="p">)</span>

<span class="c"># Stack and synchronize between beat events</span>
<span class="c"># This time, we&#39;ll use the mean value (default) instead of median</span>
<span class="n">beat_mfcc_delta</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">sync</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">mfcc</span><span class="p">,</span> <span class="n">mfcc_delta</span><span class="p">]),</span>
                                       <span class="n">beat_frames</span><span class="p">)</span>

<span class="c"># Compute chroma features from the harmonic signal</span>
<span class="n">chromagram</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">chromagram</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_harmonic</span><span class="p">,</span>
                                        <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
                                        <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>

<span class="c"># Aggregate chroma features between beat events</span>
<span class="c"># We&#39;ll use the median value of each feature between beat frames</span>
<span class="n">beat_chroma</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">sync</span><span class="p">(</span><span class="n">chromagram</span><span class="p">,</span>
                                   <span class="n">beat_frames</span><span class="p">,</span>
                                   <span class="n">aggregate</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">)</span>

<span class="c"># Finally, stack all beat-synchronous features together</span>
<span class="n">beat_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">beat_chroma</span><span class="p">,</span> <span class="n">beat_mfcc_delta</span><span class="p">])</span>
</pre></div>
</td></tr></table></div>
<p>This example builds on tools we&#8217;ve already covered in the <a class="reference internal" href="#quickstart"><em>quickstart example</em></a>, so here we&#8217;ll focus just on the new parts.</p>
<p>The first difference is the use of the <a class="reference internal" href="librosa.html#effects"><em>effects module</em></a> for time-series
harmonic-percussive separation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">y_harmonic</span><span class="p">,</span> <span class="n">y_percussive</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">effects</span><span class="o">.</span><span class="n">hpss</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of this line is that the time series <tt class="docutils literal"><span class="pre">y</span></tt> has been separated into two time
series, containing the harmonic (tonal) and percussive (transient) portions of the
signal.  Each of <tt class="docutils literal"><span class="pre">y_harmonic</span></tt> and <tt class="docutils literal"><span class="pre">y_percussive</span></tt> have the same shape and duration
as <tt class="docutils literal"><span class="pre">y</span></tt>.</p>
<p>The motivation for this kind of operation is two-fold: first, percussive elements
tend to be stronger indicators of rhythmic content, and can help provide more stable
beat tracking results; second, percussive elements can pollute tonal feature
representations (such as chroma) by contributing energy across all frequency bands, so
we&#8217;d be better off without them.</p>
<p>Next, we introduce the <a class="reference internal" href="librosa.html#feature"><em>feature module</em></a> and extract the Mel-frequency
cepstral coefficients from the raw signal <tt class="docutils literal"><span class="pre">y</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">mfcc</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">mfcc</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
<p>The output of this function is the matrix <tt class="docutils literal"><span class="pre">mfcc</span></tt>, which is an <em>numpy.ndarray</em> of
size <tt class="docutils literal"><span class="pre">(n_mfcc,</span> <span class="pre">T)</span></tt> (where <tt class="docutils literal"><span class="pre">T</span></tt> denotes the track duration in frames).  Note that we
use the same <tt class="docutils literal"><span class="pre">hop_length</span></tt> here as in the beat tracker, so the detected <tt class="docutils literal"><span class="pre">beat_frames</span></tt>
values correspond to columns of <tt class="docutils literal"><span class="pre">mfcc</span></tt>.</p>
<p>The first type of feature manipulation we introduce is <tt class="docutils literal"><span class="pre">delta</span></tt>, which computes
(smoothed) first-order differences among columns of its input:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">mfcc_delta</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">delta</span><span class="p">(</span><span class="n">mfcc</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting matrix <tt class="docutils literal"><span class="pre">mfcc_delta</span></tt> has the same shape as the input <tt class="docutils literal"><span class="pre">mfcc</span></tt>.</p>
<p>The second type of feature manipulation is <tt class="docutils literal"><span class="pre">sync</span></tt>, which aggregates columns of its
input between sample indices (e.g., beat frames):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">beat_mfcc_delta</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">sync</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">mfcc</span><span class="p">,</span> <span class="n">mfcc_delta</span><span class="p">]),</span>
                                       <span class="n">beat_frames</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we&#8217;ve vertically stacked the <tt class="docutils literal"><span class="pre">mfcc</span></tt> and <tt class="docutils literal"><span class="pre">mfcc_delta</span></tt> matrices together.  The
result of this operation is a matrix <tt class="docutils literal"><span class="pre">beat_mfcc_delta</span></tt> with the same number of rows
as its input, but the number of columns depends on <tt class="docutils literal"><span class="pre">beat_frames</span></tt>.  Each column
<tt class="docutils literal"><span class="pre">beat_mfcc_delta[:,</span> <span class="pre">k]</span></tt> will be the <em>average</em> of input columns between
<tt class="docutils literal"><span class="pre">beat_frames[k]</span></tt> and <tt class="docutils literal"><span class="pre">beat_frames[k+1]</span></tt>.  (<tt class="docutils literal"><span class="pre">beat_frames</span></tt> will be expanded to
span the full range <tt class="docutils literal"><span class="pre">[0,</span> <span class="pre">T]</span></tt> so that all data is accounted for.)</p>
<p>Next, we compute a chromagram using just the harmonic component:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">chromagram</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">chromagram</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_harmonic</span><span class="p">,</span>
                                        <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
                                        <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>
</pre></div>
</div>
<p>After this line, <tt class="docutils literal"><span class="pre">chromagram</span></tt> will be a <em>numpy.ndarray</em> of size <tt class="docutils literal"><span class="pre">(12,</span> <span class="pre">T)</span></tt>, and
each row corresponds to a pitch class (e.g., <em>C</em>, <em>C#</em>, etc.).  Each column of
<tt class="docutils literal"><span class="pre">chromagram</span></tt> is normalized by its peak value, though this behavior can be overridden
by setting the <tt class="docutils literal"><span class="pre">norm</span></tt> parameter.</p>
<p>Once we have the chromagram and list of beat frames, we again synchronize the chroma
between beat events:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">beat_chroma</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">sync</span><span class="p">(</span><span class="n">chromagram</span><span class="p">,</span>
                                   <span class="n">beat_frames</span><span class="p">,</span>
                                   <span class="n">aggregate</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">)</span>
</pre></div>
</div>
<p>This time, we&#8217;ve replaced the default aggregate operation (<em>average</em>, as used above
for MFCCs) with the <em>median</em>.  In general, any statistical summarization function can
be supplied here, including <cite>np.max()</cite>, <cite>np.min()</cite>, <cite>np.std()</cite>, etc.</p>
<p>Finally, the all features are vertically stacked again:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">beat_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">beat_chroma</span><span class="p">,</span> <span class="n">beat_mfcc_delta</span><span class="p">])</span>
</pre></div>
</div>
<p>resulting in a feature matrix <tt class="docutils literal"><span class="pre">beat_features</span></tt> of dimension
<tt class="docutils literal"><span class="pre">(12</span> <span class="pre">+</span> <span class="pre">13</span> <span class="pre">+</span> <span class="pre">13,</span> <span class="pre">#</span> <span class="pre">beat</span> <span class="pre">intervals)</span></tt>.</p>
</div>
<div class="section" id="more-examples">
<h2>More examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¶</a></h2>
<p>More example scripts are provided in the <a class="reference external" href="https://github.com/bmcfee/librosa/tree/master/examples">examples</a> folder.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2014, Dawen Liang, Brian McFee, Matt McVicar, Colin Raffel.<br/>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>