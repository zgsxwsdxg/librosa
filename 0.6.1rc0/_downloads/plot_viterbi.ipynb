{
  "nbformat_minor": 0,
  "nbformat": 4,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "name": "python",
      "version": "3.5.5",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "mimetype": "text/x-python"
    }
  },
  "cells": [
    {
      "source": [
        "%matplotlib inline"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "\n# Viterbi decoding\n\n\nThis notebook demonstrates how to use Viterbi decoding to impose temporal\nsmoothing on frame-wise state predictions.\n\nOur working example will be the problem of silence/non-silence detection.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Code source: Brian McFee\n# License: ISC\n\n##################\n# Standard imports\nfrom __future__ import print_function\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\n\nimport librosa.display"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "Load an example signal\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "y, sr = librosa.load('audio/sir_duke_slow.mp3')\n\n\n# And compute the spectrogram magnitude and phase\nS_full, phase = librosa.magphase(librosa.stft(y))\n\n\n###################\n# Plot the spectrum\nplt.figure(figsize=(12, 4))\nlibrosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                         y_axis='log', x_axis='time', sr=sr)\nplt.colorbar()\nplt.tight_layout()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "As you can see, there are periods of silence and\nnon-silence throughout this recording.\n\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# As a first step, we can plot the root-mean-square energy (RMSE)\nrmse = librosa.feature.rmse(y=y)[0]\n\ntimes = librosa.frames_to_time(np.arange(len(rmse)))\n\nplt.figure(figsize=(12, 4))\nplt.plot(times, rmse)\nplt.axhline(0.02, color='r', alpha=0.5)\nplt.xlabel('Time')\nplt.ylabel('RMSE')\nplt.axis('tight')\nplt.tight_layout()\n\n# The red line at 0.02 indicates a reasonable threshold for silence detection.\n# However, the RMSE curve occasionally dips below the threshold momentarily,\n# and we would prefer the detector to not count these brief dips as silence.\n# This is where the Viterbi algorithm comes in handy!"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "As a first step, we will convert the raw RMSE score\ninto a likelihood (probability) by logistic mapping\n\n  $P[V=1 | x] = \\frac{\\exp(x - \\tau)}{1 + \\exp(x - \\tau)}$\n\nwhere $x$ denotes the RMSE value and $\\tau=0.02$ is our threshold.\nThe variable $V$ indicates whether the signal is non-silent (1) or silent (0).\n\nWe'll normalize the RMSE by its standard deviation to expand the\nrange of the probability vector\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "r_normalized = (rmse - 0.02) / np.std(rmse)\np = np.exp(r_normalized) / (1 + np.exp(r_normalized))\n\n# We can plot the probability curve over time:\n\nplt.figure(figsize=(12, 4))\nplt.plot(times, p, label='P[V=1|x]')\nplt.axhline(0.5, color='r', alpha=0.5, label='Descision threshold')\nplt.xlabel('Time')\nplt.axis('tight')\nplt.legend()\nplt.tight_layout()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "which looks much like the first plot, but with the decision threshold\nshifted to 0.5.  A simple silence detector would classify each frame\nindependently of its neighbors, which would result in the following plot:\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "plt.figure(figsize=(12, 6))\nax = plt.subplot(2,1,1)\nlibrosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                         y_axis='log', x_axis='time', sr=sr)\nplt.subplot(2,1,2, sharex=ax)\nplt.step(times, p>=0.5, label='Non-silent')\nplt.xlabel('Time')\nplt.axis('tight')\nplt.ylim([0, 1.05])\nplt.legend()\nplt.tight_layout()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "We can do better using the Viterbi algorithm.\nWe'll use state 0 to indicate silent, and 1 to indicate non-silent.\nWe'll assume that a silent frame is equally likely to be followed\nby silence or non-silence, but that non-silence is slightly\nmore likely to be followed by non-silence.\nThis is accomplished by building a self-loop transition matrix,\nwhere `transition[i, j]` is the probability of moving from state\n`i` to state `j` in the next frame.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "transition = librosa.sequence.transition_loop(2, [0.5, 0.6])\nprint(transition)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "Our `p` variable only indicates the probability of non-silence,\nso we need to also compute the probability of silence as its complement.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "full_p = np.vstack([1 - p, p])\nprint(full_p)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "Now, we're ready to decode!\nWe'll use `viterbi_discriminative` here, since the inputs are\nstate likelihoods conditional on data (in our case, data is rmse).\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "states = librosa.sequence.viterbi_discriminative(full_p, transition)\n\n# sphinx_gallery_thumbnail_number = 5\nplt.figure(figsize=(12, 6))\nax = plt.subplot(2,1,1)\nlibrosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                         y_axis='log', x_axis='time', sr=sr)\nplt.xlabel('')\nax.tick_params(labelbottom=False)\nplt.subplot(2, 1, 2, sharex=ax)\nplt.step(times, p>=0.5, label='Frame-wise')\nplt.step(times, states, linestyle='--', color='orange', label='Viterbi')\nplt.xlabel('Time')\nplt.axis('tight')\nplt.ylim([0, 1.05])\nplt.legend()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "source": [
        "Note how the Viterbi output has fewer state changes than the frame-wise\npredictor, and it is less sensitive to momentary dips in energy.\nThis is controlled directly by the transition matrix.\nA higher self-transition probability means that the decoder is less\nlikely to change states.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}